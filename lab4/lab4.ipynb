{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fully connected neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('drug200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>11.567</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>16</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>12.006</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>52</td>\n",
       "      <td>M</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>9.894</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>14.020</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11.349</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0     23   F    HIGH        HIGH   25.355  DrugY\n",
       "1     47   M     LOW        HIGH   13.093  drugC\n",
       "2     47   M     LOW        HIGH   10.114  drugC\n",
       "3     28   F  NORMAL        HIGH    7.798  drugX\n",
       "4     61   F     LOW        HIGH   18.043  DrugY\n",
       "..   ...  ..     ...         ...      ...    ...\n",
       "195   56   F     LOW        HIGH   11.567  drugC\n",
       "196   16   M     LOW        HIGH   12.006  drugC\n",
       "197   52   M  NORMAL        HIGH    9.894  drugX\n",
       "198   23   M  NORMAL      NORMAL   14.020  drugX\n",
       "199   40   F     LOW      NORMAL   11.349  drugX\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'] = pd.Categorical(df['Sex'])\n",
    "df['BP'] = pd.Categorical(df['BP'])\n",
    "df['Cholesterol'] = pd.Categorical(df['Cholesterol'])\n",
    "df['Drug'] = pd.Categorical(df['Drug'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.select_dtypes(include='category').columns:\n",
    "    if column=='Drug':\n",
    "        continue\n",
    "    df = pd.concat([df, pd.get_dummies(df[column], prefix=column)],axis=1)\n",
    "    df.drop([column],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df['Drug'].cat.codes\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Drug',axis=1), dummy_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    scale = StandardScaler().fit(X_train[[column]])\n",
    "    X_train[[column]] = scale.transform(X_train[[column]])\n",
    "    X_test[[column]] = scale.transform(X_test[[column]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=9, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "5/5 [==============================] - 0s 960us/step - loss: 1.7164 - accuracy: 0.0720\n",
      "Epoch 2/25\n",
      "5/5 [==============================] - 0s 831us/step - loss: 1.6634 - accuracy: 0.0628\n",
      "Epoch 3/25\n",
      "5/5 [==============================] - 0s 770us/step - loss: 1.6273 - accuracy: 0.0942\n",
      "Epoch 4/25\n",
      "5/5 [==============================] - 0s 946us/step - loss: 1.5897 - accuracy: 0.0997\n",
      "Epoch 5/25\n",
      "5/5 [==============================] - 0s 882us/step - loss: 1.5437 - accuracy: 0.1936\n",
      "Epoch 6/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5239 - accuracy: 0.3185\n",
      "Epoch 7/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4683 - accuracy: 0.4079\n",
      "Epoch 8/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4249 - accuracy: 0.4872\n",
      "Epoch 9/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4040 - accuracy: 0.4714\n",
      "Epoch 10/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3840 - accuracy: 0.5476\n",
      "Epoch 11/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3179 - accuracy: 0.6466\n",
      "Epoch 12/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2742 - accuracy: 0.6720\n",
      "Epoch 13/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2746 - accuracy: 0.5970\n",
      "Epoch 14/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1955 - accuracy: 0.6907\n",
      "Epoch 15/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2516 - accuracy: 0.5657\n",
      "Epoch 16/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1880 - accuracy: 0.6078\n",
      "Epoch 17/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1507 - accuracy: 0.5976\n",
      "Epoch 18/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0829 - accuracy: 0.6336\n",
      "Epoch 19/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0190 - accuracy: 0.6709\n",
      "Epoch 20/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0024 - accuracy: 0.6806\n",
      "Epoch 21/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9841 - accuracy: 0.6816\n",
      "Epoch 22/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9548 - accuracy: 0.7118\n",
      "Epoch 23/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9587 - accuracy: 0.6881\n",
      "Epoch 24/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9355 - accuracy: 0.7109\n",
      "Epoch 25/25\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9185 - accuracy: 0.7178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f231c546e50>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27387172, 0.1684021 , 0.0681873 , 0.12414631, 0.3653926 ],\n",
       "       [0.48998672, 0.08895952, 0.02025304, 0.10800317, 0.29279754],\n",
       "       [0.07679363, 0.11225224, 0.02348699, 0.0434214 , 0.74404573],\n",
       "       [0.33614996, 0.12480108, 0.08417764, 0.1681133 , 0.286758  ],\n",
       "       [0.9115796 , 0.01152067, 0.00186362, 0.04490192, 0.03013421],\n",
       "       [0.5658961 , 0.08734766, 0.0624288 , 0.14480363, 0.13952376],\n",
       "       [0.8307367 , 0.02693978, 0.00369932, 0.07280026, 0.06582397],\n",
       "       [0.21920843, 0.12462015, 0.02433743, 0.07620132, 0.55563265],\n",
       "       [0.2844744 , 0.17773117, 0.10910533, 0.15153931, 0.27714974],\n",
       "       [0.19008805, 0.15016937, 0.07452508, 0.11055429, 0.4746632 ],\n",
       "       [0.4862642 , 0.1181571 , 0.04509943, 0.13536642, 0.21511279],\n",
       "       [0.28424355, 0.11612594, 0.03005511, 0.10402436, 0.46555105],\n",
       "       [0.686741  , 0.0634446 , 0.01958595, 0.10497835, 0.12525007],\n",
       "       [0.5096785 , 0.08728599, 0.02038228, 0.11688644, 0.26576677],\n",
       "       [0.21940872, 0.15504624, 0.27289006, 0.16880128, 0.18385366],\n",
       "       [0.5867799 , 0.0798948 , 0.01152343, 0.06742302, 0.25437889],\n",
       "       [0.21227175, 0.15846393, 0.2621484 , 0.16924845, 0.19786748],\n",
       "       [0.18821618, 0.15774718, 0.06970515, 0.10524131, 0.4790902 ],\n",
       "       [0.2661412 , 0.13991363, 0.05188792, 0.12907402, 0.41298324],\n",
       "       [0.8053732 , 0.03410509, 0.0079977 , 0.07108869, 0.08143528],\n",
       "       [0.3093243 , 0.13159928, 0.1525134 , 0.18016176, 0.22640125],\n",
       "       [0.3367986 , 0.1273652 , 0.11509918, 0.15965904, 0.26107794],\n",
       "       [0.17554244, 0.1464449 , 0.12560251, 0.12572998, 0.42668012],\n",
       "       [0.8805658 , 0.01418083, 0.00277408, 0.06375693, 0.0387224 ],\n",
       "       [0.81372887, 0.02551498, 0.00645481, 0.0828791 , 0.07142222],\n",
       "       [0.89062804, 0.01298261, 0.00223664, 0.05885304, 0.03529975],\n",
       "       [0.27292734, 0.14397529, 0.08122838, 0.15826577, 0.34360328],\n",
       "       [0.19615087, 0.13493578, 0.02344104, 0.05393534, 0.59153694],\n",
       "       [0.85435104, 0.02226104, 0.00287168, 0.06774069, 0.05277561],\n",
       "       [0.3244862 , 0.14887099, 0.07428207, 0.13979001, 0.3125707 ],\n",
       "       [0.526695  , 0.10257566, 0.03403903, 0.12721756, 0.20947269],\n",
       "       [0.27316365, 0.1738183 , 0.04646312, 0.1027041 , 0.40385085],\n",
       "       [0.5084246 , 0.08906677, 0.01994682, 0.12199155, 0.2605703 ],\n",
       "       [0.63314444, 0.07779549, 0.01455789, 0.09336285, 0.18113929],\n",
       "       [0.2027111 , 0.17161444, 0.21224235, 0.16962558, 0.24380657],\n",
       "       [0.83033705, 0.03233178, 0.0033311 , 0.05922632, 0.07477377],\n",
       "       [0.37869903, 0.11343611, 0.11123126, 0.16409191, 0.23254167],\n",
       "       [0.45900518, 0.1068868 , 0.04483924, 0.16424115, 0.22502762],\n",
       "       [0.65802234, 0.07529767, 0.01254085, 0.08708057, 0.16705851],\n",
       "       [0.3551659 , 0.1288127 , 0.06250043, 0.16416982, 0.2893512 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 4, 0, 0, 0, 0, 4, 0, 4, 0, 4, 0, 0, 2, 0, 2, 4, 4, 0, 0, 0,\n",
       "       4, 0, 0, 0, 4, 4, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array([i.argmax() for i in pred])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 4, 3, 0, 0, 0, 4, 1, 4, 1, 4, 0, 1, 2, 0, 2, 4, 3, 0, 2, 4,\n",
       "       4, 0, 0, 0, 3, 4, 0, 4, 0, 3, 3, 0, 1, 0, 4, 1, 0, 1])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.array([i.argmax() for i in y_test])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44547189819724287"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73        15\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       1.00      0.67      0.80         3\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.67      0.73      0.70        11\n",
      "\n",
      "    accuracy                           0.62        40\n",
      "   macro avg       0.45      0.48      0.45        40\n",
      "weighted avg       0.47      0.62      0.53        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0  0  0]\n",
      " [ 5  0  0  0  1]\n",
      " [ 1  0  2  0  0]\n",
      " [ 2  0  0  0  3]\n",
      " [ 3  0  0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN - [lab4_2.ipynb](lab4_2.ipynb) (Done via google collab)\n",
    "\n",
    "To run it you should download https://www.kaggle.com/alxmamaev/flowers-recognition and unpack to google drive folder that contains .ipynb file.\n",
    "\n",
    "Then run all cells and wait for your entire life - images are loading. \n",
    "\n",
    "You can turn DEBUG = True to ensure you are not wasting your time and images are actually loading. But your browser may be incapable of renderingh such amount of output, so clear the output of loading cell time to time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout, GlobalMaxPooling1D, SimpleRNN\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SMSSpamCollection.csv', sep='\\t', names=['target', 'headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = pd.Categorical(data['target'])\n",
    "data['target'] = data['target'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600,) (400,)\n"
     ]
    }
   ],
   "source": [
    "text = data['headline'].values\n",
    "labels = data['target'].values\n",
    "text_train, text_test, y_train, y_test = train_test_split(text, labels, test_size=0.2, random_state=42)\n",
    "print(text_train.shape, text_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.headline.str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "maxlen = 135\n",
    "embedding_size = 32\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(text_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(text_train)\n",
    "x_test = tokenizer.texts_to_sequences(text_test)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 135, 32)           160000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 135, 32)           2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 162,113\n",
      "Trainable params: 162,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=maxlen))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 1s 101ms/step - loss: 0.6789 - accuracy: 0.5274 - val_loss: 0.5046 - val_accuracy: 0.8500\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4813 - accuracy: 0.8634 - val_loss: 0.4560 - val_accuracy: 0.8500\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4351 - accuracy: 0.8643 - val_loss: 0.4341 - val_accuracy: 0.8500\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4178 - accuracy: 0.8583 - val_loss: 0.4251 - val_accuracy: 0.8500\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.4052 - accuracy: 0.8622 - val_loss: 0.4217 - val_accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size=512, validation_data=(x_test, y_test), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.0%\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x_test)>0.5\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
